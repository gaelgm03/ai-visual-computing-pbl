{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# DS Evaluation Pipeline: Matching & Metrics\n\n**Purpose**: Load pre-computed `.npz` files, run the full matching pipeline (ArcFace embedding + geometric + descriptor + fusion), and evaluate with standard biometric metrics.\n\n**Prerequisites**:\n- Google Drive with `face-auth-data/mast3r_outputs/` (enrollment `.npz`) and `face-auth-data/auth_probes/` (probe `.npz`)\n- These files are generated by CS-1's `scripts/prepare_public_dataset.py`\n- **v2 templates**: `.npz` files include `face_embedding` (512-dim ArcFace). Use `scripts/augment_npz_with_embeddings.py` to add embeddings to v1 files.\n\n**No MASt3R model loading needed** — this notebook works entirely with pre-computed data.\n\n**GPU**: If a T4 GPU is available, descriptor matching is automatically accelerated.\n\n---"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# Cell 1: Environment Setup\n# ============================================================\n# Install dependencies and mount Google Drive.\n# ============================================================\n\n!pip install -q open3d plotly scikit-learn tqdm insightface onnxruntime-gpu\n\nimport torch\nif torch.cuda.is_available():\n    gpu_name = torch.cuda.get_device_name(0)\n    vram_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n    print(f\"GPU: {gpu_name} ({vram_gb:.1f} GB) — descriptor matching will use GPU\")\nelse:\n    print(\"No GPU — descriptor matching will use CPU (still works, just slower)\")\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nimport os\nSHARED_DIR = \"/content/drive/MyDrive/face-auth-data\"\nENROLLMENT_DIR = f\"{SHARED_DIR}/mast3r_outputs/archive/mast3r_outputs\"\nPROBE_DIR = f\"{SHARED_DIR}/mast3r_outputs/archive/auth_probes\"\n\nprint(f\"\\nEnrollment dir: {ENROLLMENT_DIR}\")\nprint(f\"Probe dir:      {PROBE_DIR}\")\nprint(f\"Enrollment dir exists: {os.path.isdir(ENROLLMENT_DIR)}\")\nprint(f\"Probe dir exists:      {os.path.isdir(PROBE_DIR)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 2: Clone Repo & Configure Python Path\n",
    "# ============================================================\n",
    "\n",
    "import sys\n",
    "\n",
    "REPO_URL = \"https://github.com/gaelgm03/ai-visual-computing-pbl.git\"\n",
    "BRANCH = \"main\"  # Change to your feature branch if needed\n",
    "REPO_DIR = \"/content/ai-visual-computing-pbl\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone --depth 1 {REPO_URL} {REPO_DIR}\n",
    "\n",
    "%cd {REPO_DIR}\n",
    "!git fetch origin && git checkout {BRANCH} && git pull origin {BRANCH}\n",
    "\n",
    "sys.path.insert(0, REPO_DIR)\n",
    "print(f\"\\nRepo ready at {REPO_DIR}, branch: {BRANCH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 3: Discover Available .npz Files\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def discover_data(enrollment_dir, probe_dir):\n",
    "    \"\"\"Find all enrollment/probe pairs by matching person names.\"\"\"\n",
    "    enrollments = {}\n",
    "    probes = {}\n",
    "\n",
    "    if os.path.isdir(enrollment_dir):\n",
    "        for f in os.listdir(enrollment_dir):\n",
    "            if f.endswith(\"_enrollment.npz\"):\n",
    "                name = f.replace(\"_enrollment.npz\", \"\")\n",
    "                enrollments[name] = os.path.join(enrollment_dir, f)\n",
    "\n",
    "    if os.path.isdir(probe_dir):\n",
    "        for f in os.listdir(probe_dir):\n",
    "            if f.endswith(\"_probe.npz\"):\n",
    "                name = f.replace(\"_probe.npz\", \"\")\n",
    "                probes[name] = os.path.join(probe_dir, f)\n",
    "\n",
    "    subjects = sorted(set(enrollments.keys()) & set(probes.keys()))\n",
    "    return subjects, enrollments, probes\n",
    "\n",
    "\n",
    "subjects, enrollments, probes = discover_data(ENROLLMENT_DIR, PROBE_DIR)\n",
    "\n",
    "print(f\"Found {len(subjects)} subjects with both enrollment and probe data:\")\n",
    "for s in subjects:\n",
    "    e = np.load(enrollments[s])\n",
    "    p = np.load(probes[s])\n",
    "    print(f\"  {s}: enrollment={e['point_cloud'].shape[0]:,} pts, \"\n",
    "          f\"probe={p['point_cloud'].shape[0]:,} pts\")\n",
    "\n",
    "if not subjects:\n",
    "    print(\"\\nNo matching enrollment/probe pairs found!\")\n",
    "    print(f\"  Check that {ENROLLMENT_DIR} has *_enrollment.npz files\")\n",
    "    print(f\"  and {PROBE_DIR} has *_probe.npz files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# Cell 4: Inspect Data Format\n# ============================================================\n\nsample = np.load(enrollments[subjects[0]], allow_pickle=True)\nprint(\"Keys:\", list(sample.keys()))\nfor key in sample.keys():\n    arr = sample[key]\n    if hasattr(arr, 'shape'):\n        print(f\"  {key}: shape={arr.shape}, dtype={arr.dtype}\")\n    else:\n        print(f\"  {key}: {type(arr)}\")\n\n# Check descriptor normalization\ndesc = sample[\"descriptors\"]\nnorms = np.linalg.norm(desc, axis=1)\nprint(f\"\\nDescriptor norms: min={norms.min():.3f}, max={norms.max():.3f}, mean={norms.mean():.3f}\")\nif abs(norms.mean() - 1.0) > 0.1:\n    print(\"Descriptors are NOT unit-normalized — the matcher will normalize internally.\")\nelse:\n    print(\"Descriptors appear unit-normalized.\")\n\n# Check for ArcFace embedding (v2 templates)\nHAS_EMBEDDINGS = \"face_embedding\" in sample\nif HAS_EMBEDDINGS:\n    emb = sample[\"face_embedding\"]\n    print(f\"\\nArcFace embedding: shape={emb.shape}, norm={np.linalg.norm(emb):.4f}\")\n    print(\"Template version: v2 (with ArcFace identity embeddings)\")\nelse:\n    print(\"\\nNo face_embedding found — using v1 templates (MASt3R descriptors only).\")\n    print(\"Run scripts/augment_npz_with_embeddings.py to add ArcFace embeddings.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 5: Visualize Point Cloud (CS2DS-share.md §4.2)\n",
    "# ============================================================\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def visualize_point_cloud(points, colors=None, title=\"Point Cloud\", max_points=10000):\n",
    "    \"\"\"Interactive 3D point cloud visualization.\"\"\"\n",
    "    if len(points) > max_points:\n",
    "        idx = np.random.choice(len(points), max_points, replace=False)\n",
    "        points = points[idx]\n",
    "        if colors is not None:\n",
    "            colors = colors[idx]\n",
    "\n",
    "    if colors is not None:\n",
    "        color_str = [f'rgb({r},{g},{b})' for r, g, b in colors]\n",
    "    else:\n",
    "        color_str = points[:, 2]\n",
    "\n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=points[:, 0], y=points[:, 1], z=points[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(size=1.5, color=color_str, opacity=0.8),\n",
    "    )])\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        scene=dict(aspectmode='data'),\n",
    "        width=800, height=600,\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Show enrollment and probe side by side for the first subject\n",
    "person = subjects[0]\n",
    "e_data = np.load(enrollments[person])\n",
    "p_data = np.load(probes[person])\n",
    "\n",
    "fig = visualize_point_cloud(\n",
    "    e_data[\"point_cloud\"], e_data[\"colors\"],\n",
    "    title=f\"{person} — Enrollment ({e_data['point_cloud'].shape[0]:,} pts)\"\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = visualize_point_cloud(\n",
    "    p_data[\"point_cloud\"], p_data[\"colors\"],\n",
    "    title=f\"{person} — Probe ({p_data['point_cloud'].shape[0]:,} pts)\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# Cell 6: Initialize Matchers\n# ============================================================\n\nfrom core.matching.geometric_matcher import ICPGeometricMatcher\nfrom core.matching.descriptor_matcher import NNDescriptorMatcher\nfrom core.matching.embedding_matcher import ArcFaceEmbeddingMatcher\nfrom core.matching.score_fusion import WeightedFusion, MultiModalFusion\n\nconfig = {\n    \"icp\": {\n        \"max_iterations\": 50,\n        \"convergence_threshold\": 1e-6,\n        \"max_correspondence_distance\": 0.05,\n    },\n    \"chamfer_alpha\": 30.0,\n    \"geometric_subsample\": 10000,\n    \"descriptor_subsample\": 15000,\n    \"match_ratio_weight\": 0.4,\n    \"avg_similarity_weight\": 0.6,\n    # Fusion weights (tuned on public dataset evaluation)\n    \"embedding_weight\": 0.40,\n    \"geometric_weight\": 0.10,\n    \"descriptor_weight\": 0.50,\n    \"accept_threshold\": 0.65,\n}\n\ngeo_matcher = ICPGeometricMatcher(config)\ndesc_matcher = NNDescriptorMatcher(config)\nemb_matcher = ArcFaceEmbeddingMatcher(config)\nlegacy_fusion = WeightedFusion(config)\nfusion = MultiModalFusion(config)\n\nprint(\"Matchers initialized:\")\nprint(f\"  Geometric:  ICP + Chamfer (subsample={config['geometric_subsample']})\")\nprint(f\"  Descriptor: Reciprocal NN (subsample={config['descriptor_subsample']})\")\nprint(f\"  Embedding:  ArcFace cosine similarity (512-dim)\")\nprint(f\"  Fusion:     embedding={config['embedding_weight']}, geo={config['geometric_weight']}, desc={config['descriptor_weight']}, threshold={config['accept_threshold']}\")\nif not HAS_EMBEDDINGS:\n    print(\"\\n  WARNING: .npz files lack face_embedding — embedding matcher will be skipped.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# Cell 7: Single Genuine Pair Test\n# ============================================================\n\nimport time\n\nperson = subjects[0]\nenrollment = np.load(enrollments[person], allow_pickle=True)\nprobe = np.load(probes[person], allow_pickle=True)\n\nprint(f\"=== Genuine pair: {person} vs {person} ===\")\n\nt0 = time.time()\ngeo_result = geo_matcher.compare(probe[\"point_cloud\"], enrollment[\"point_cloud\"])\nt1 = time.time()\ndesc_result = desc_matcher.compare(\n    probe[\"descriptors\"], enrollment[\"descriptors\"],\n    probe[\"point_cloud\"], enrollment[\"point_cloud\"],\n)\nt2 = time.time()\n\n# ArcFace embedding matching (if available)\nemb_result = None\nif HAS_EMBEDDINGS and \"face_embedding\" in probe and \"face_embedding\" in enrollment:\n    emb_result = emb_matcher.compare(probe[\"face_embedding\"], enrollment[\"face_embedding\"])\nt3 = time.time()\n\n# Fusion\nif emb_result is not None:\n    final_result = fusion.fuse({\"embedding\": emb_result, \"geometric\": geo_result, \"descriptor\": desc_result})\nelse:\n    final_result = legacy_fusion.fuse(geo_result, desc_result)\n\nprint(f\"  Geometric:  {geo_result.score:.3f}  (Chamfer: {geo_result.details.get('chamfer_distance', 'N/A')})\")\nprint(f\"  Descriptor: {desc_result.score:.3f}  (Match ratio: {desc_result.details.get('match_ratio', 0):.3f}, \"\n      f\"Avg sim: {desc_result.details.get('avg_cosine_similarity', 0):.3f})\")\nif emb_result:\n    print(f\"  Embedding:  {emb_result.score:.3f}  (Raw cosine: {emb_result.details.get('raw_cosine_similarity', 0):.4f})\")\nprint(f\"  Fused:      {final_result.score:.3f}  is_match={final_result.is_match}\")\nprint(f\"  Time: geo={t1-t0:.2f}s, desc={t2-t1:.2f}s, emb={t3-t2:.4f}s\")\nprint(f\"  Backend: desc={desc_result.details.get('backend', 'unknown')}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# Cell 8: Single Impostor Pair Test\n# ============================================================\n\nif len(subjects) >= 2:\n    person_a = subjects[0]\n    person_b = subjects[1]\n    enrollment_a = np.load(enrollments[person_a], allow_pickle=True)\n    probe_b = np.load(probes[person_b], allow_pickle=True)\n\n    geo_result = geo_matcher.compare(probe_b[\"point_cloud\"], enrollment_a[\"point_cloud\"])\n    desc_result = desc_matcher.compare(\n        probe_b[\"descriptors\"], enrollment_a[\"descriptors\"],\n        probe_b[\"point_cloud\"], enrollment_a[\"point_cloud\"],\n    )\n\n    emb_result = None\n    if HAS_EMBEDDINGS and \"face_embedding\" in probe_b and \"face_embedding\" in enrollment_a:\n        emb_result = emb_matcher.compare(probe_b[\"face_embedding\"], enrollment_a[\"face_embedding\"])\n\n    if emb_result is not None:\n        final_result = fusion.fuse({\"embedding\": emb_result, \"geometric\": geo_result, \"descriptor\": desc_result})\n    else:\n        final_result = legacy_fusion.fuse(geo_result, desc_result)\n\n    print(f\"=== Impostor pair: {person_b} vs {person_a} ===\")\n    print(f\"  Geometric:  {geo_result.score:.3f}\")\n    print(f\"  Descriptor: {desc_result.score:.3f}\")\n    if emb_result:\n        print(f\"  Embedding:  {emb_result.score:.3f}  (Raw cosine: {emb_result.details.get('raw_cosine_similarity', 0):.4f})\")\n    print(f\"  Fused:      {final_result.score:.3f}  is_match={final_result.is_match}\")\nelse:\n    print(\"Need at least 2 subjects for impostor test\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# Cell 9: All-vs-All Matching\n# ============================================================\n\nfrom tqdm import tqdm\n\nsimilarities = []\nlabels = []  # 1 = genuine, 0 = impostor\npair_info = []\n\n# Cache loaded data to avoid re-reading\nenrollment_cache = {}\nprobe_cache = {}\nfor s in subjects:\n    enrollment_cache[s] = np.load(enrollments[s], allow_pickle=True)\n    probe_cache[s] = np.load(probes[s], allow_pickle=True)\n\ntotal_pairs = len(subjects) ** 2\nprint(f\"Running {total_pairs} pairs ({len(subjects)} subjects x {len(subjects)} enrollments)...\")\n\nfor probe_person in tqdm(subjects, desc=\"Matching\"):\n    p_data = probe_cache[probe_person]\n\n    for enroll_person in subjects:\n        e_data = enrollment_cache[enroll_person]\n        is_genuine = int(probe_person == enroll_person)\n\n        geo_result = geo_matcher.compare(\n            p_data[\"point_cloud\"], e_data[\"point_cloud\"]\n        )\n        desc_result = desc_matcher.compare(\n            p_data[\"descriptors\"], e_data[\"descriptors\"],\n            p_data[\"point_cloud\"], e_data[\"point_cloud\"],\n        )\n\n        # ArcFace embedding matching\n        emb_score = 0.0\n        emb_raw_cosine = 0.0\n        if HAS_EMBEDDINGS and \"face_embedding\" in p_data and \"face_embedding\" in e_data:\n            emb_result = emb_matcher.compare(p_data[\"face_embedding\"], e_data[\"face_embedding\"])\n            emb_score = emb_result.score\n            emb_raw_cosine = emb_result.details.get(\"raw_cosine_similarity\", 0.0)\n            final_result = fusion.fuse({\n                \"embedding\": emb_result,\n                \"geometric\": geo_result,\n                \"descriptor\": desc_result,\n            })\n        else:\n            final_result = legacy_fusion.fuse(geo_result, desc_result)\n\n        similarities.append(final_result.score)\n        labels.append(is_genuine)\n        pair_info.append({\n            \"probe\": probe_person,\n            \"enrollment\": enroll_person,\n            \"genuine\": is_genuine,\n            \"geo_score\": geo_result.score,\n            \"desc_score\": desc_result.score,\n            \"emb_score\": emb_score,\n            \"emb_raw_cosine\": emb_raw_cosine,\n            \"fused_score\": final_result.score,\n        })\n\nsimilarities = np.array(similarities)\nlabels = np.array(labels)\n\nprint(f\"\\nTotal pairs: {len(similarities)}\")\nprint(f\"  Genuine:  {labels.sum()} ({labels.mean()*100:.1f}%)\")\nprint(f\"  Impostor: {(1-labels).sum().astype(int)} ({(1-labels).mean()*100:.1f}%)\")\nprint(f\"\\nGenuine score range:  [{similarities[labels==1].min():.3f}, {similarities[labels==1].max():.3f}]\")\nprint(f\"Impostor score range: [{similarities[labels==0].min():.3f}, {similarities[labels==0].max():.3f}]\")\n\nif HAS_EMBEDDINGS:\n    emb_scores = np.array([p['emb_score'] for p in pair_info])\n    print(f\"\\nArcFace Embedding scores:\")\n    print(f\"  Genuine:  [{emb_scores[labels==1].min():.3f}, {emb_scores[labels==1].max():.3f}]\")\n    print(f\"  Impostor: [{emb_scores[labels==0].min():.3f}, {emb_scores[labels==0].max():.3f}]\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 10: Evaluate with FaceRecognitionEvaluator\n",
    "# ============================================================\n",
    "\n",
    "from core.evaluation import FaceRecognitionEvaluator\n",
    "\n",
    "evaluator = FaceRecognitionEvaluator(threshold=config[\"accept_threshold\"])\n",
    "eval_result = evaluator.evaluate(\n",
    "    similarities=similarities.tolist(),\n",
    "    labels=labels.tolist(),\n",
    "    plot=True,\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"EVALUATION RESULTS (threshold={eval_result.threshold:.2f})\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"  Accuracy:  {eval_result.accuracy:.3f}\")\n",
    "print(f\"  Precision: {eval_result.precision:.3f}\")\n",
    "print(f\"  Recall:    {eval_result.recall:.3f}\")\n",
    "print(f\"  F1 Score:  {eval_result.f1_score:.3f}\")\n",
    "print(f\"  FAR:       {eval_result.far:.3f}\")\n",
    "print(f\"  TAR:       {eval_result.tar:.3f}\")\n",
    "print(f\"  EER:       {eval_result.eer:.3f} (at threshold={eval_result.eer_threshold:.3f})\")\n",
    "print(f\"  AUC:       {eval_result.auc_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# Cell 11: Per-Path Score Distributions\n# ============================================================\n\nimport matplotlib.pyplot as plt\n\ngeo_scores = np.array([p['geo_score'] for p in pair_info])\ndesc_scores = np.array([p['desc_score'] for p in pair_info])\nemb_scores = np.array([p['emb_score'] for p in pair_info])\nfused_scores = np.array([p['fused_score'] for p in pair_info])\n\nn_plots = 4 if HAS_EMBEDDINGS else 3\nfig, axes = plt.subplots(1, n_plots, figsize=(6 * n_plots, 5))\n\nscore_sets = [\n    (geo_scores, 'Geometric (ICP + Chamfer)'),\n    (desc_scores, 'Descriptor (Reciprocal NN)'),\n]\nif HAS_EMBEDDINGS:\n    score_sets.append((emb_scores, 'ArcFace Embedding (Cosine)'))\nscore_sets.append((fused_scores, 'Fused (Multi-Modal)'))\n\nfor ax, (scores, title) in zip(axes, score_sets):\n    ax.hist(scores[labels == 1], bins=20, alpha=0.7, label='Genuine', color='green')\n    ax.hist(scores[labels == 0], bins=20, alpha=0.7, label='Impostor', color='red')\n    ax.axvline(x=config['accept_threshold'], color='black', linestyle='--', label='Threshold')\n    ax.set_title(title)\n    ax.set_xlabel('Score')\n    ax.set_ylabel('Count')\n    ax.legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 12: Score Matrix Heatmap\n",
    "# ============================================================\n",
    "\n",
    "n = len(subjects)\n",
    "score_matrix = fused_scores.reshape(n, n)\n",
    "\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=score_matrix,\n",
    "    x=subjects,\n",
    "    y=subjects,\n",
    "    colorscale='RdYlGn',\n",
    "    zmin=0, zmax=1,\n",
    "    text=np.round(score_matrix, 2),\n",
    "    texttemplate=\"%{text}\",\n",
    "))\n",
    "fig.update_layout(\n",
    "    title=\"Matching Score Matrix (Probe vs Enrollment)\",\n",
    "    xaxis_title=\"Enrollment\",\n",
    "    yaxis_title=\"Probe\",\n",
    "    width=max(500, 80 * n),\n",
    "    height=max(400, 70 * n),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# Cell 13: Weight Optimization (Grid Search)\n# ============================================================\n# If ArcFace embeddings available: 3-way search (emb, geo, desc)\n# Otherwise: 2-way search (geo, desc) as before\n# ============================================================\n\nfrom sklearn.metrics import f1_score as sk_f1_score\n\nresults_grid = []\n\nif HAS_EMBEDDINGS:\n    # 3-way grid search: embedding_weight + geometric_weight + descriptor_weight = 1.0\n    step = 0.05\n    for w_emb in np.arange(0.0, 1.0 + step, step):\n        for w_geo in np.arange(0.0, 1.0 - w_emb + step, step):\n            w_desc = round(1.0 - w_emb - w_geo, 2)\n            if w_desc < -0.01:\n                continue\n            w_desc = max(0.0, w_desc)\n\n            fused = w_emb * emb_scores + w_geo * geo_scores + w_desc * desc_scores\n\n            best_f1, best_thresh = 0.0, 0.5\n            for thresh in np.arange(0.1, 0.95, 0.01):\n                preds = (fused >= thresh).astype(int)\n                f1_val = sk_f1_score(labels, preds, zero_division=0)\n                if f1_val > best_f1:\n                    best_f1 = f1_val\n                    best_thresh = thresh\n\n            results_grid.append({\n                'w_emb': round(w_emb, 2),\n                'w_geo': round(w_geo, 2),\n                'w_desc': round(w_desc, 2),\n                'best_f1': best_f1,\n                'best_threshold': round(best_thresh, 2),\n            })\n\n    best = max(results_grid, key=lambda x: x['best_f1'])\n\n    # Print top 20 results\n    top_results = sorted(results_grid, key=lambda x: x['best_f1'], reverse=True)[:20]\n    print(f\"{'Emb':>6} {'Geo':>6} {'Desc':>6} {'Best F1':>8} {'Threshold':>10}\")\n    print(\"-\" * 45)\n    for r in top_results:\n        marker = \" <-- BEST\" if r == best else \"\"\n        print(f\"{r['w_emb']:>6.2f} {r['w_geo']:>6.2f} {r['w_desc']:>6.2f} \"\n              f\"{r['best_f1']:>8.3f} {r['best_threshold']:>10.2f}{marker}\")\n\n    print(f\"\\nOptimal: embedding_weight={best['w_emb']:.2f}, \"\n          f\"geometric_weight={best['w_geo']:.2f}, \"\n          f\"descriptor_weight={best['w_desc']:.2f}, \"\n          f\"threshold={best['best_threshold']:.2f}, \"\n          f\"F1={best['best_f1']:.3f}\")\n\nelse:\n    # Legacy 2-way grid search\n    alphas = np.arange(0.0, 1.05, 0.05)\n    for alpha in alphas:\n        beta = 1.0 - alpha\n        fused = alpha * geo_scores + beta * desc_scores\n\n        best_f1, best_thresh = 0.0, 0.5\n        for thresh in np.arange(0.1, 0.95, 0.01):\n            preds = (fused >= thresh).astype(int)\n            f1_val = sk_f1_score(labels, preds, zero_division=0)\n            if f1_val > best_f1:\n                best_f1 = f1_val\n                best_thresh = thresh\n\n        results_grid.append({\n            'w_emb': 0.0,\n            'w_geo': round(alpha, 2),\n            'w_desc': round(beta, 2),\n            'best_f1': best_f1,\n            'best_threshold': round(best_thresh, 2),\n        })\n\n    best = max(results_grid, key=lambda x: x['best_f1'])\n\n    print(f\"{'Alpha':>6} {'Beta':>6} {'Best F1':>8} {'Threshold':>10}\")\n    print(\"-\" * 35)\n    for r in results_grid:\n        marker = \" <-- BEST\" if r == best else \"\"\n        print(f\"{r['w_geo']:>6.2f} {r['w_desc']:>6.2f} {r['best_f1']:>8.3f} {r['best_threshold']:>10.2f}{marker}\")\n\n    print(f\"\\nOptimal: geometric_weight={best['w_geo']:.2f}, \"\n          f\"descriptor_weight={best['w_desc']:.2f}, \"\n          f\"threshold={best['best_threshold']:.2f}, \"\n          f\"F1={best['best_f1']:.3f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# Cell 14: Re-evaluate with Optimal Parameters\n# ============================================================\n\noptimal_similarities = (\n    best['w_emb'] * emb_scores +\n    best['w_geo'] * geo_scores +\n    best['w_desc'] * desc_scores\n)\noptimal_evaluator = FaceRecognitionEvaluator(threshold=best['best_threshold'])\n\noptimal_result = optimal_evaluator.evaluate(\n    optimal_similarities.tolist(),\n    labels.tolist(),\n    plot=True,\n)\n\nprint(f\"\\n{'='*50}\")\nprint(f\"OPTIMIZED RESULTS\")\nprint(f\"{'='*50}\")\nprint(f\"  Weights:   emb={best['w_emb']:.2f}, geo={best['w_geo']:.2f}, desc={best['w_desc']:.2f}\")\nprint(f\"  Threshold: {best['best_threshold']:.2f}\")\nprint(f\"  Accuracy:  {optimal_result.accuracy:.3f}\")\nprint(f\"  F1 Score:  {optimal_result.f1_score:.3f}\")\nprint(f\"  FAR:       {optimal_result.far:.3f}\")\nprint(f\"  TAR:       {optimal_result.tar:.3f}\")\nprint(f\"  EER:       {optimal_result.eer:.3f}\")\nprint(f\"  AUC:       {optimal_result.auc_score:.3f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# Cell 15: Recommended config.yaml Values\n# ============================================================\n\nprint(\"=\" * 60)\nprint(\"RECOMMENDED CONFIG.YAML VALUES\")\nprint(\"=\" * 60)\nprint(f\"\"\"\nmatching:\n  embedding_weight: {best['w_emb']:.2f}     # ArcFace identity (primary)\n  geometric_weight: {best['w_geo']:.2f}     # ICP + Chamfer (supplementary)\n  descriptor_weight: {best['w_desc']:.2f}    # MASt3R descriptors\n  accept_threshold: {best['best_threshold']:.2f}    # Optimized threshold\n\"\"\")\nprint(f\"Based on {len(subjects)} subjects, {len(similarities)} total pairs\")\nprint(f\"F1={optimal_result.f1_score:.3f}, EER={optimal_result.eer:.3f}, AUC={optimal_result.auc_score:.3f}\")\n\nif HAS_EMBEDDINGS:\n    # Also evaluate embedding-only performance (for comparison)\n    emb_evaluator = FaceRecognitionEvaluator(threshold=0.5)\n    emb_only = emb_evaluator.evaluate(emb_scores.tolist(), labels.tolist(), plot=False)\n    print(f\"\\n--- ArcFace Embedding ONLY (for comparison) ---\")\n    print(f\"  EER: {emb_only.eer:.3f}  AUC: {emb_only.auc_score:.3f}  F1: {emb_only.f1_score:.3f}\")\n\n# Save figures to Drive\nfigures_dir = f\"{SHARED_DIR}/evaluation_results/figures\"\noptimal_evaluator.evaluate(\n    optimal_similarities.tolist(),\n    labels.tolist(),\n    plot=False,\n    save_dir=figures_dir,\n)\nprint(f\"\\nFigures saved to {figures_dir}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Before Closing: Push to GitHub!\n",
    "\n",
    "Colab sessions are temporary. Push any changes before closing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run before closing:\n",
    "\n",
    "# %cd /content/ai-visual-computing-pbl\n",
    "# !git add -A\n",
    "# !git status\n",
    "# !git commit -m \"feat(ds1): add evaluation results\"\n",
    "# !git push origin {BRANCH}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}