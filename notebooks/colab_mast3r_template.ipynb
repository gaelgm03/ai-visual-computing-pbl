{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MASt3R Face Authentication - Colab Template\n",
        "\n",
        "**Purpose**: This notebook provides a template for team members to work with MASt3R on Google Colab.\n",
        "\n",
        "**Who should use this**:\n",
        "- CS-2: For testing visualization with real point cloud data\n",
        "- DS-1: For developing matching algorithms\n",
        "- DS-2: For evaluation and anti-spoofing analysis\n",
        "\n",
        "**What you'll need**:\n",
        "- A Google account with Google Drive access\n",
        "- The shared `face-auth-data` folder on Google Drive\n",
        "\n",
        "---\n",
        "\n",
        "## How to use this notebook\n",
        "\n",
        "1. **First time**: Go to `File > Save a copy in Drive` to create your own copy\n",
        "2. **Every session**: Run cells 1-3 to set up the environment\n",
        "3. **Before closing**: Push your changes to GitHub (see final cell)\n",
        "\n",
        "**Important**: Colab sessions are temporary! Always push your code changes to GitHub before closing.\n",
        "\n",
        "---\n",
        "\n",
        "*Author: CS-1 | Last updated: 2026-02*"
      ],
      "metadata": {
        "id": "header-cell"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 1: GPU Check & Google Drive Mount\n",
        "\n",
        "This cell verifies that a GPU is available and mounts your Google Drive.\n",
        "\n",
        "**What is Google Drive Mount?**\n",
        "- It makes your Drive files accessible as if they were local files\n",
        "- Your Drive will appear at `/content/drive/MyDrive/`\n",
        "- This is where we store large files (model weights, datasets)"
      ],
      "metadata": {
        "id": "cell1-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Cell 1: GPU Check + Google Drive Mount\n",
        "# ============================================================\n",
        "# This cell must be run at the START of every Colab session.\n",
        "# It checks for GPU availability and mounts Google Drive.\n",
        "# ============================================================\n",
        "\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# ----- GPU Check -----\n",
        "# MASt3R requires a GPU for reasonable performance.\n",
        "# If no GPU is detected, go to: Runtime > Change runtime type > T4 GPU\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    raise RuntimeError(\n",
        "        \"\\n\" + \"=\"*60 + \"\\n\" +\n",
        "        \"ERROR: No GPU detected!\\n\" +\n",
        "        \"Please enable GPU: Runtime > Change runtime type > T4 GPU\\n\" +\n",
        "        \"=\"*60\n",
        "    )\n",
        "\n",
        "# Print GPU information\n",
        "gpu_name = torch.cuda.get_device_name(0)\n",
        "vram_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "print(f\"‚úÖ GPU detected: {gpu_name}\")\n",
        "print(f\"   VRAM: {vram_gb:.1f} GB\")\n",
        "\n",
        "# ----- Mount Google Drive -----\n",
        "# This allows access to shared data files stored on Drive.\n",
        "# You'll be prompted to authorize access the first time.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ----- Set up shared data directory -----\n",
        "# SHARED_DIR is where all team data lives:\n",
        "#   - checkpoints/: MASt3R model weights (~1GB)\n",
        "#   - raw_captures/: Webcam images captured by CS-1\n",
        "#   - mast3r_outputs/: Pre-computed point clouds & descriptors\n",
        "#   - evaluation_results/: DS team experiment outputs\n",
        "\n",
        "SHARED_DIR = \"/content/drive/MyDrive/face-auth-data\"\n",
        "\n",
        "# Create subdirectories if they don't exist\n",
        "subdirs = [\"checkpoints\", \"raw_captures\", \"mast3r_outputs\", \"evaluation_results\"]\n",
        "for subdir in subdirs:\n",
        "    os.makedirs(f\"{SHARED_DIR}/{subdir}\", exist_ok=True)\n",
        "\n",
        "print(f\"\\n‚úÖ Google Drive mounted\")\n",
        "print(f\"   Shared data directory: {SHARED_DIR}\")\n",
        "\n",
        "# List what's in the shared directory\n",
        "print(f\"\\nüìÅ Contents of shared directory:\")\n",
        "for item in os.listdir(SHARED_DIR):\n",
        "    item_path = os.path.join(SHARED_DIR, item)\n",
        "    if os.path.isdir(item_path):\n",
        "        n_files = len(os.listdir(item_path))\n",
        "        print(f\"   üìÇ {item}/ ({n_files} items)\")\n",
        "    else:\n",
        "        print(f\"   üìÑ {item}\")"
      ],
      "metadata": {
        "id": "cell1-code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 2: Clone GitHub Repository\n",
        "\n",
        "This cell clones our team's code repository from GitHub.\n",
        "\n",
        "**Why clone every session?**\n",
        "- Colab's filesystem is temporary (erased when session ends)\n",
        "- GitHub is our \"source of truth\" for all code\n",
        "- This ensures you always have the latest code\n",
        "\n",
        "**Important**: Update `REPO_URL` with your team's actual repository URL!"
      ],
      "metadata": {
        "id": "cell2-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Cell 2: Clone GitHub Repository\n",
        "# ============================================================\n",
        "# Clone the team's repository from GitHub.\n",
        "# This gives you access to all source code.\n",
        "# ============================================================\n",
        "\n",
        "# ----- CONFIGURATION (UPDATE THESE!) -----\n",
        "# Replace with your team's actual repository URL\n",
        "REPO_URL = \"https://github.com/YOUR-TEAM/face-auth-mast3r.git\"  # <-- UPDATE THIS!\n",
        "\n",
        "# Which branch to check out (usually 'develop' for development work)\n",
        "BRANCH = \"develop\"\n",
        "\n",
        "# Your git identity (needed for commits)\n",
        "GIT_EMAIL = \"your-email@example.com\"  # <-- UPDATE THIS!\n",
        "GIT_NAME = \"Your Name\"                # <-- UPDATE THIS!\n",
        "# ------------------------------------------\n",
        "\n",
        "import os\n",
        "\n",
        "REPO_DIR = \"/content/repo\"\n",
        "\n",
        "# Clone if not already cloned\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    print(f\"Cloning repository from {REPO_URL}...\")\n",
        "    !git clone {REPO_URL} {REPO_DIR}\n",
        "else:\n",
        "    print(f\"Repository already exists at {REPO_DIR}\")\n",
        "\n",
        "# Change to repo directory\n",
        "%cd {REPO_DIR}\n",
        "\n",
        "# Fetch latest changes and checkout the specified branch\n",
        "!git fetch origin\n",
        "!git checkout {BRANCH}\n",
        "!git pull origin {BRANCH}\n",
        "\n",
        "# Configure git identity for commits\n",
        "!git config user.email \"{GIT_EMAIL}\"\n",
        "!git config user.name \"{GIT_NAME}\"\n",
        "\n",
        "print(f\"\\n‚úÖ Repository ready at {REPO_DIR}\")\n",
        "print(f\"   Branch: {BRANCH}\")\n",
        "\n",
        "# Show recent commits\n",
        "print(f\"\\nüìú Recent commits:\")\n",
        "!git log --oneline -5"
      ],
      "metadata": {
        "id": "cell2-code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 3: Symlink Large Files from Drive\n",
        "\n",
        "This cell creates symbolic links from Google Drive to the repository.\n",
        "\n",
        "**Why symlinks?**\n",
        "- Large files (model weights, datasets) live on Google Drive\n",
        "- They're too big for GitHub (100MB limit)\n",
        "- Symlinks let the code access them as if they were in the repo\n",
        "\n",
        "**What is a symlink?**\n",
        "- A \"shortcut\" that points to another file/folder\n",
        "- Like a Windows shortcut, but for Linux"
      ],
      "metadata": {
        "id": "cell3-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Cell 3: Symlink Large Files from Google Drive\n",
        "# ============================================================\n",
        "# Create symbolic links so code can access Drive data.\n",
        "# These symlinks are gitignored - they won't be committed.\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "\n",
        "REPO_DIR = \"/content/repo\"\n",
        "SHARED_DIR = \"/content/drive/MyDrive/face-auth-data\"\n",
        "\n",
        "# ----- Symlink 1: Model checkpoints -----\n",
        "# The MASt3R model weights file is ~1GB\n",
        "checkpoints_dir = f\"{REPO_DIR}/checkpoints\"\n",
        "os.makedirs(checkpoints_dir, exist_ok=True)\n",
        "\n",
        "checkpoint_file = \"MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric.pth\"\n",
        "checkpoint_src = f\"{SHARED_DIR}/checkpoints/{checkpoint_file}\"\n",
        "checkpoint_dst = f\"{checkpoints_dir}/{checkpoint_file}\"\n",
        "\n",
        "if os.path.exists(checkpoint_src):\n",
        "    if not os.path.exists(checkpoint_dst):\n",
        "        os.symlink(checkpoint_src, checkpoint_dst)\n",
        "    print(f\"‚úÖ Checkpoint linked: {checkpoint_file}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Checkpoint not found on Drive: {checkpoint_src}\")\n",
        "    print(f\"   CS-1 needs to upload it to the shared folder.\")\n",
        "\n",
        "# ----- Symlink 2: Pre-computed MASt3R outputs -----\n",
        "# These .npz files contain point clouds and descriptors\n",
        "# DS team uses these to develop matching algorithms\n",
        "data_shared_link = f\"{REPO_DIR}/data_shared\"\n",
        "mast3r_outputs = f\"{SHARED_DIR}/mast3r_outputs\"\n",
        "\n",
        "if os.path.exists(mast3r_outputs):\n",
        "    if not os.path.exists(data_shared_link):\n",
        "        os.symlink(mast3r_outputs, data_shared_link)\n",
        "    print(f\"‚úÖ MASt3R outputs linked to: data_shared/\")\n",
        "\n",
        "    # List available .npz files\n",
        "    npz_files = [f for f in os.listdir(mast3r_outputs) if f.endswith('.npz')]\n",
        "    if npz_files:\n",
        "        print(f\"   Available templates:\")\n",
        "        for f in npz_files[:10]:  # Show first 10\n",
        "            print(f\"     - {f}\")\n",
        "        if len(npz_files) > 10:\n",
        "            print(f\"     ... and {len(npz_files) - 10} more\")\n",
        "    else:\n",
        "        print(f\"   No .npz files yet (CS-1 will generate these)\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  MASt3R outputs folder not found: {mast3r_outputs}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Drive data symlinked into repository\")"
      ],
      "metadata": {
        "id": "cell3-code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 4: Install MASt3R Dependencies\n",
        "\n",
        "This cell installs the Python packages that MASt3R needs.\n",
        "\n",
        "**Note**: This takes 3-5 minutes and must be run every session.\n",
        "\n",
        "**What gets installed?**\n",
        "- PyTorch (deep learning framework)\n",
        "- Open3D (point cloud processing)\n",
        "- Various scientific Python packages"
      ],
      "metadata": {
        "id": "cell4-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Cell 4: Install MASt3R Dependencies\n",
        "# ============================================================\n",
        "# Install Python packages required by MASt3R.\n",
        "# This takes 3-5 minutes and must be done every session.\n",
        "# ============================================================\n",
        "\n",
        "%%bash\n",
        "# Check if MASt3R is available as submodule or standalone\n",
        "if [ -d \"/content/repo/third_party/mast3r\" ]; then\n",
        "    MAST3R_DIR=\"/content/repo/third_party/mast3r\"\n",
        "    echo \"Using MASt3R from repository submodule\"\n",
        "else\n",
        "    # Clone MASt3R standalone if submodule not initialized\n",
        "    if [ ! -d \"/content/mast3r\" ]; then\n",
        "        echo \"Cloning MASt3R repository...\"\n",
        "        git clone --recursive https://github.com/naver/mast3r.git /content/mast3r\n",
        "    fi\n",
        "    MAST3R_DIR=\"/content/mast3r\"\n",
        "    echo \"Using standalone MASt3R clone\"\n",
        "fi\n",
        "\n",
        "cd $MAST3R_DIR\n",
        "\n",
        "# Install MASt3R requirements\n",
        "echo \"Installing MASt3R requirements...\"\n",
        "pip install -q -r requirements.txt\n",
        "\n",
        "# Install DUSt3R requirements (MASt3R depends on DUSt3R)\n",
        "echo \"Installing DUSt3R requirements...\"\n",
        "pip install -q -r dust3r/requirements.txt\n",
        "\n",
        "# Optional: Compile CUDA kernels for faster inference\n",
        "# This may fail on some Colab instances, but it's not critical\n",
        "echo \"Attempting to compile CUDA kernels (optional)...\"\n",
        "cd dust3r/croco/models/curope/\n",
        "python setup.py build_ext --inplace 2>/dev/null || echo \"CUDA kernel compilation skipped (non-critical)\"\n",
        "\n",
        "echo \"\"\n",
        "echo \"‚úÖ Dependencies installed!\""
      ],
      "metadata": {
        "id": "cell4-code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 5: Configure Python Path & Load MASt3R Model\n",
        "\n",
        "This cell sets up Python import paths and loads the MASt3R model.\n",
        "\n",
        "**What does this do?**\n",
        "- Adds MASt3R and our project to Python's import path\n",
        "- Loads the pre-trained model into GPU memory\n",
        "\n",
        "**After this cell**: You can use `model` for inference!"
      ],
      "metadata": {
        "id": "cell5-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Cell 5: Configure Python Path & Load MASt3R Model\n",
        "# ============================================================\n",
        "# Set up Python imports and load the MASt3R model.\n",
        "# After this cell, you can use 'model' for inference.\n",
        "# ============================================================\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# ----- Configure Python path -----\n",
        "# This tells Python where to find MASt3R and our project code\n",
        "\n",
        "# Check for MASt3R location (submodule or standalone)\n",
        "if os.path.exists(\"/content/repo/third_party/mast3r\"):\n",
        "    MAST3R_PATH = \"/content/repo/third_party/mast3r\"\n",
        "else:\n",
        "    MAST3R_PATH = \"/content/mast3r\"\n",
        "\n",
        "# Add paths to Python's import search path\n",
        "paths_to_add = [\n",
        "    \"/content/repo\",           # Our project\n",
        "    MAST3R_PATH,                # MASt3R\n",
        "    f\"{MAST3R_PATH}/dust3r\",   # DUSt3R (MASt3R dependency)\n",
        "]\n",
        "\n",
        "for path in paths_to_add:\n",
        "    if path not in sys.path:\n",
        "        sys.path.insert(0, path)\n",
        "\n",
        "print(f\"‚úÖ Python paths configured\")\n",
        "print(f\"   MASt3R location: {MAST3R_PATH}\")\n",
        "\n",
        "# ----- Import MASt3R -----\n",
        "try:\n",
        "    from mast3r.model import AsymmetricMASt3R\n",
        "    print(f\"‚úÖ MASt3R module imported\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Failed to import MASt3R: {e}\")\n",
        "    print(f\"   Make sure Cell 4 (dependencies) ran successfully.\")\n",
        "\n",
        "# ----- Load the model -----\n",
        "print(f\"\\n‚è≥ Loading MASt3R model (this takes 30-60 seconds)...\")\n",
        "\n",
        "# Load from Hugging Face Hub (auto-downloads if not cached)\n",
        "model = AsymmetricMASt3R.from_pretrained(\n",
        "    \"naver/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric\"\n",
        ")\n",
        "\n",
        "# Move model to GPU\n",
        "device = torch.device(\"cuda\")\n",
        "model = model.to(device)\n",
        "model.eval()  # Set to evaluation mode (disables dropout, etc.)\n",
        "\n",
        "# Print model info\n",
        "n_params = sum(p.numel() for p in model.parameters()) / 1e6\n",
        "print(f\"\\n‚úÖ MASt3R model loaded!\")\n",
        "print(f\"   Parameters: {n_params:.1f}M\")\n",
        "print(f\"   Device: {device}\")\n",
        "\n",
        "# Check GPU memory usage\n",
        "allocated = torch.cuda.memory_allocated(0) / 1e9\n",
        "total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "print(f\"   GPU Memory: {allocated:.1f}GB / {total:.1f}GB used\")"
      ],
      "metadata": {
        "id": "cell5-code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Cell 6: Load Pre-computed Data (For DS Team)\n",
        "\n",
        "**Who needs this?**: DS-1 and DS-2\n",
        "\n",
        "This cell shows how to load `.npz` files that CS-1 has pre-computed.\n",
        "These files contain point clouds and descriptors that you can use\n",
        "to develop matching algorithms **without running MASt3R yourself**.\n",
        "\n",
        "**Contents of each .npz file:**\n",
        "- `point_cloud`: (N, 3) - 3D coordinates of face surface\n",
        "- `descriptors`: (N, D) - Feature vectors for matching\n",
        "- `confidence`: (N,) - How confident each point is\n",
        "- `colors`: (N, 3) - RGB color per point"
      ],
      "metadata": {
        "id": "cell6-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Cell 6: Load Pre-computed Data (For DS Team)\n",
        "# ============================================================\n",
        "# Load .npz files containing point clouds and descriptors.\n",
        "# DS team uses these to develop matching algorithms.\n",
        "# No MASt3R inference needed!\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "SHARED_DIR = \"/content/drive/MyDrive/face-auth-data/mast3r_outputs\"\n",
        "\n",
        "def load_template(filename: str) -> dict:\n",
        "    \"\"\"\n",
        "    Load a pre-computed face template from the shared Drive folder.\n",
        "\n",
        "    Args:\n",
        "        filename: Name of the .npz file (e.g., \"alice_enrollment.npz\")\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing:\n",
        "        - point_cloud: (N, 3) - 3D face surface coordinates\n",
        "        - descriptors: (N, D) - Dense feature vectors per point\n",
        "        - confidence: (N,) - Confidence value per point\n",
        "        - colors: (N, 3) - RGB color per point\n",
        "\n",
        "    Example:\n",
        "        >>> template = load_template(\"alice_enrollment.npz\")\n",
        "        >>> print(template[\"point_cloud\"].shape)  # (N, 3)\n",
        "    \"\"\"\n",
        "    filepath = os.path.join(SHARED_DIR, filename)\n",
        "\n",
        "    if not os.path.exists(filepath):\n",
        "        raise FileNotFoundError(\n",
        "            f\"Template not found: {filepath}\\n\"\n",
        "            f\"Available files: {os.listdir(SHARED_DIR) if os.path.exists(SHARED_DIR) else 'Directory not found'}\"\n",
        "        )\n",
        "\n",
        "    data = np.load(filepath, allow_pickle=True)\n",
        "\n",
        "    return {\n",
        "        \"point_cloud\": data[\"point_cloud\"],   # (N, 3) float32\n",
        "        \"descriptors\": data[\"descriptors\"],   # (N, D) float32\n",
        "        \"confidence\": data[\"confidence\"],     # (N,) float32\n",
        "        \"colors\": data[\"colors\"],             # (N, 3) uint8\n",
        "    }\n",
        "\n",
        "\n",
        "# ----- Example usage -----\n",
        "# List available templates\n",
        "if os.path.exists(SHARED_DIR):\n",
        "    npz_files = [f for f in os.listdir(SHARED_DIR) if f.endswith('.npz')]\n",
        "    print(f\"üìÇ Available templates in {SHARED_DIR}:\")\n",
        "    for f in npz_files:\n",
        "        filepath = os.path.join(SHARED_DIR, f)\n",
        "        size_mb = os.path.getsize(filepath) / 1e6\n",
        "        print(f\"   {f} ({size_mb:.1f} MB)\")\n",
        "\n",
        "    # Load the first available template as an example\n",
        "    if npz_files:\n",
        "        print(f\"\\nüì• Loading example: {npz_files[0]}\")\n",
        "        example = load_template(npz_files[0])\n",
        "        print(f\"   Point cloud shape: {example['point_cloud'].shape}\")\n",
        "        print(f\"   Descriptor shape: {example['descriptors'].shape}\")\n",
        "        print(f\"   Total points: {len(example['point_cloud'])}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Shared directory not found: {SHARED_DIR}\")\n",
        "    print(f\"   CS-1 needs to upload pre-computed templates to Drive.\")"
      ],
      "metadata": {
        "id": "cell6-code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 7: Visualize a Point Cloud\n",
        "\n",
        "**Recommended first step**: See what the data looks like!\n",
        "\n",
        "This cell creates an interactive 3D visualization of a face point cloud.\n",
        "You can rotate, zoom, and explore the 3D structure."
      ],
      "metadata": {
        "id": "cell7-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Cell 7: Visualize a Point Cloud\n",
        "# ============================================================\n",
        "# Create an interactive 3D visualization of the face.\n",
        "# This helps you understand the data before writing algorithms.\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "def visualize_point_cloud(points: np.ndarray, colors: np.ndarray = None,\n",
        "                         title: str = \"Point Cloud\", max_points: int = 10000):\n",
        "    \"\"\"\n",
        "    Create an interactive 3D visualization of a point cloud.\n",
        "\n",
        "    Args:\n",
        "        points: (N, 3) array of 3D coordinates\n",
        "        colors: (N, 3) array of RGB colors (optional)\n",
        "        title: Title for the plot\n",
        "        max_points: Subsample to this many points for performance\n",
        "\n",
        "    Returns:\n",
        "        plotly Figure object (displayed automatically in Colab)\n",
        "    \"\"\"\n",
        "    # Subsample if too many points (for rendering performance)\n",
        "    if len(points) > max_points:\n",
        "        idx = np.random.choice(len(points), max_points, replace=False)\n",
        "        points = points[idx]\n",
        "        if colors is not None:\n",
        "            colors = colors[idx]\n",
        "        print(f\"Subsampled to {max_points} points for visualization\")\n",
        "\n",
        "    # Prepare colors\n",
        "    if colors is not None:\n",
        "        # Convert RGB to plotly color format\n",
        "        color_strings = [f'rgb({r},{g},{b})' for r, g, b in colors]\n",
        "    else:\n",
        "        # Default: color by Z-depth\n",
        "        color_strings = points[:, 2]\n",
        "\n",
        "    # Create the 3D scatter plot\n",
        "    fig = go.Figure(data=[go.Scatter3d(\n",
        "        x=points[:, 0],\n",
        "        y=points[:, 1],\n",
        "        z=points[:, 2],\n",
        "        mode='markers',\n",
        "        marker=dict(\n",
        "            size=1.5,\n",
        "            color=color_strings,\n",
        "            opacity=0.8\n",
        "        )\n",
        "    )])\n",
        "\n",
        "    # Configure layout\n",
        "    fig.update_layout(\n",
        "        title=title,\n",
        "        scene=dict(\n",
        "            aspectmode='data',  # Equal aspect ratio\n",
        "            xaxis_title='X',\n",
        "            yaxis_title='Y',\n",
        "            zaxis_title='Z (depth)',\n",
        "        ),\n",
        "        width=800,\n",
        "        height=600,\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "\n",
        "# ----- Example: Visualize a loaded template -----\n",
        "# (Assuming you ran Cell 6 to load data)\n",
        "\n",
        "SHARED_DIR = \"/content/drive/MyDrive/face-auth-data/mast3r_outputs\"\n",
        "\n",
        "if os.path.exists(SHARED_DIR):\n",
        "    npz_files = [f for f in os.listdir(SHARED_DIR) if f.endswith('.npz')]\n",
        "\n",
        "    if npz_files:\n",
        "        # Load and visualize the first available template\n",
        "        template = load_template(npz_files[0])\n",
        "        fig = visualize_point_cloud(\n",
        "            template[\"point_cloud\"],\n",
        "            template[\"colors\"],\n",
        "            title=f\"Face Point Cloud: {npz_files[0]}\"\n",
        "        )\n",
        "        fig.show()\n",
        "    else:\n",
        "        print(\"No .npz files available. Creating demo with random data...\")\n",
        "        # Create a demo sphere point cloud\n",
        "        theta = np.random.uniform(0, np.pi, 5000)\n",
        "        phi = np.random.uniform(0, 2*np.pi, 5000)\n",
        "        r = 1 + 0.1 * np.random.randn(5000)\n",
        "        demo_points = np.stack([\n",
        "            r * np.sin(theta) * np.cos(phi),\n",
        "            r * np.sin(theta) * np.sin(phi),\n",
        "            r * np.cos(theta)\n",
        "        ], axis=1)\n",
        "        fig = visualize_point_cloud(demo_points, title=\"Demo: Random Sphere\")\n",
        "        fig.show()"
      ],
      "metadata": {
        "id": "cell7-code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Your Work Goes Here!\n",
        "\n",
        "Add your own cells below for:\n",
        "- **DS-1**: Matching algorithm experiments\n",
        "- **DS-2**: Evaluation and anti-spoofing analysis\n",
        "- **CS-2**: Visualization testing\n",
        "\n",
        "Remember to save your work to GitHub before the session ends!"
      ],
      "metadata": {
        "id": "your-work-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Your experiments go here!\n",
        "# ============================================================\n",
        "\n",
        "# Example: Load two templates and compare them\n",
        "# alice = load_template(\"alice_enrollment.npz\")\n",
        "# bob = load_template(\"bob_enrollment.npz\")\n",
        "#\n",
        "# # Your matching algorithm here...\n",
        "# score = your_matching_function(alice, bob)\n",
        "# print(f\"Match score: {score}\")"
      ],
      "metadata": {
        "id": "your-work-code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## ‚ö†Ô∏è Before Closing: Push to GitHub!\n",
        "\n",
        "**CRITICAL**: Colab sessions are temporary. Any code you write will be lost when the session ends unless you push it to GitHub.\n",
        "\n",
        "Run this cell to commit and push your changes."
      ],
      "metadata": {
        "id": "push-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# BEFORE CLOSING: Push Changes to GitHub\n",
        "# ============================================================\n",
        "# Run this cell to save your work before the session ends!\n",
        "# ============================================================\n",
        "\n",
        "# Uncomment the lines below when you're ready to push\n",
        "\n",
        "# %cd /content/repo\n",
        "\n",
        "# # Stage all changes\n",
        "# !git add -A\n",
        "\n",
        "# # Show what will be committed\n",
        "# !git status\n",
        "\n",
        "# # Create a commit (update the message!)\n",
        "# !git commit -m \"feat: describe your changes here\"\n",
        "\n",
        "# # Push to your branch\n",
        "# !git push origin {BRANCH}"
      ],
      "metadata": {
        "id": "push-code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Appendix: Quick Reference\n",
        "\n",
        "### Common Operations\n",
        "\n",
        "```python\n",
        "# Load a template\n",
        "template = load_template(\"alice_enrollment.npz\")\n",
        "points = template[\"point_cloud\"]    # (N, 3)\n",
        "desc = template[\"descriptors\"]      # (N, D)\n",
        "\n",
        "# Center a point cloud\n",
        "centered = points - points.mean(axis=0)\n",
        "\n",
        "# Chamfer distance between two point clouds\n",
        "from scipy.spatial import cKDTree\n",
        "d1, _ = cKDTree(cloud_b).query(cloud_a)\n",
        "d2, _ = cKDTree(cloud_a).query(cloud_b)\n",
        "chamfer = (d1.mean() + d2.mean()) / 2\n",
        "\n",
        "# Nearest neighbor matching (descriptors)\n",
        "_, idx_a2b = cKDTree(desc_b).query(desc_a)\n",
        "_, idx_b2a = cKDTree(desc_a).query(desc_b)\n",
        "# Reciprocal match: idx_a2b[i] == j AND idx_b2a[j] == i\n",
        "```\n",
        "\n",
        "### Useful Imports\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.spatial import cKDTree\n",
        "import plotly.graph_objects as go\n",
        "import open3d as o3d  # pip install open3d\n",
        "```"
      ],
      "metadata": {
        "id": "appendix"
      }
    }
  ]
}
