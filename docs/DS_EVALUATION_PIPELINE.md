# DS Evaluation Pipeline Guide

> **Updated 2026-02-10**: Added ArcFace embedding matching as the primary identity signal.
> The pipeline now supports 3-way matching (embedding + geometric + descriptor) via `MultiModalFusion`.
> Existing v1 .npz files (without `face_embedding`) can be augmented using `scripts/augment_npz_with_embeddings.py` on WSL.

This document provides step-by-step instructions for running the face authentication matching pipeline evaluation on Google Colab.

**How to run**: Create a new empty notebook on Colab and copy-paste each cell's code below in order (same approach as `technical-architecture_whole.md` Appendix C).

---

## Table of Contents

1. [Overview](#1-overview)
2. [Prerequisites](#2-prerequisites)
3. [Google Drive Data Layout](#3-google-drive-data-layout)
4. [.npz File Format](#4-npz-file-format)
5. [Execution Steps](#5-execution-steps)
6. [Interpreting Results](#6-interpreting-results)
7. [Parameter Tuning](#7-parameter-tuning)
8. [Troubleshooting](#8-troubleshooting)
9. [Directions for Accuracy Improvement](#9-directions-for-accuracy-improvement)

---

## 1. Overview

### What This Pipeline Does

Loads pre-computed `.npz` files (3D face point clouds + feature descriptors) generated by CS-1, then runs the full evaluation end-to-end:

```
Load .npz files
    |
3D point cloud visualization (plotly)
    |
Matching algorithms
  |-- Embedding Matcher : ArcFace cosine similarity (PRIMARY identity signal, added 2026-02-10)
  |-- Geometric Matcher : ICP alignment + Chamfer distance (supplementary 3D shape comparison)
  +-- Descriptor Matcher: Reciprocal nearest-neighbor matching (disabled by default, weight=0.0)
    |
Multi-Modal Score Fusion (weighted linear combination, 3-way)
    |
Evaluation metrics (FAR, TAR, EER, AUC, F1, etc.)
    |
Diagnostic plots (4 charts)
    |
Optimal parameter search (grid search over 3 weights)
```

### No MASt3R Model Loading Required

This pipeline uses only pre-computed `.npz` data. No MASt3R model download (~1 GB) or loading is needed. Runs comfortably on Colab's free tier.

### GPU Usage

When a T4 GPU is available on Colab, the Descriptor Matcher's matrix operations are automatically GPU-accelerated (orders of magnitude faster). Falls back to CPU seamlessly if no GPU is available.

---

## 2. Prerequisites

| Item | Details |
|------|---------|
| Google Colab | Free tier works. GPU runtime recommended (T4) |
| Google Drive | Access to the shared `face-auth-data` folder |
| `.npz` data | Generated by CS-1 via `scripts/prepare_public_dataset.py` and uploaded to Google Drive |

---

## 3. Google Drive Data Layout

Follows the shared folder structure defined in `technical-architecture_whole.md` §14 "Development Workflow & Task Ownership". This pipeline uses files under `mast3r_outputs/archive/`.

```
Google Drive (shared folder)
+-- face-auth-data/
    |-- checkpoints/                     # MASt3R weights (not used by this pipeline)
    |-- datasets/                        # DS: public dataset source images
    |
    |-- mast3r_outputs/
    |   +-- archive/
    |       |-- mast3r_outputs/          # Enrollment .npz files
    |       |   |-- alice_enrollment.npz
    |       |   |-- bob_enrollment.npz
    |       |   +-- ...
    |       +-- auth_probes/             # Authentication probe .npz files
    |           |-- alice_probe.npz
    |           |-- bob_probe.npz
    |           +-- ...
    |
    +-- evaluation_results/              # Output directory (written by this pipeline)
        +-- figures/
```

> **Note**: For shared drives, the path may be `/content/drive/Shareddrives/<drive_name>/` instead of `/content/drive/MyDrive/`. Adjust `SHARED_DIR` in Cell 1 accordingly.

---

## 4. .npz File Format

Each `.npz` file contains the following arrays:

| Key | Shape | Dtype | Description |
|-----|-------|-------|-------------|
| `point_cloud` | `(N, 3)` | `float32` | 3D coordinates (x, y, z) in meters |
| `descriptors` | `(N, 24)` | `float32` | MASt3R feature vectors. **Not L2-normalized** |
| `confidence` | `(N,)` | `float32` | MASt3R confidence. `>1` indicates reliable points (not in [0,1] range) |
| `colors` | `(N, 3)` | `uint8` | RGB color (0-255) |
| `face_embedding` | `(512,)` | `float32` | ArcFace identity embedding, L2-normalized. **v2.0 only** (added 2026-02-10) |
| `metadata` | scalar | `str` | JSON string (user_id, capture time, frame count, etc.) |

### Important Notes

- **Template versions**: v1.0 files do not have `face_embedding`. Use `scripts/augment_npz_with_embeddings.py` (on WSL) to add ArcFace embeddings to existing .npz files. v2.0 files include `face_embedding` from the start. (Added 2026-02-10)
- **Descriptors are not normalized**: MASt3R output descriptors do not have unit L2 norm. The Descriptor Matcher normalizes them internally.
- **Descriptors lack identity discrimination**: MASt3R descriptors are designed for view correspondence, not person identification. The descriptor weight is 0.0 by default. (Added 2026-02-10)
- **Confidence range**: `confidence` values are positive reals in `[0, +inf)`. Values `>=1.0` are considered reliable (see `config.yaml` `confidence_threshold: 1.5`).
- **Color format**: RGB order (not OpenCV's BGR). Can be used directly for visualization.

---

## 5. Execution Steps

### Preparation: Create a Colab Notebook

1. Go to https://colab.research.google.com
2. Create a new empty notebook
3. **Runtime > Change runtime type > T4 GPU**
4. Copy-paste and run each cell below **one at a time**

> **Reference**: The code is also available in `notebooks/ds_evaluation_pipeline.ipynb`, but since Colab cannot directly execute cloned `.ipynb` files reliably, copy-paste from this document is the recommended approach.

---

### Cell 1: GPU Check + Google Drive Mount + Dependency Install

```python
# ============================================================
# Cell 1: Environment Setup
# ============================================================

!nvidia-smi
!pip install -q open3d plotly scikit-learn tqdm insightface onnxruntime-gpu

import torch
if torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name(0)
    vram_gb = torch.cuda.get_device_properties(0).total_memory / 1e9
    print(f"GPU: {gpu_name} ({vram_gb:.1f} GB) — descriptor matching will use GPU")
else:
    print("No GPU — descriptor matching will use CPU (still works, just slower)")

from google.colab import drive
drive.mount('/content/drive')

import os
SHARED_DIR = "/content/drive/MyDrive/face-auth-data"
ENROLLMENT_DIR = f"{SHARED_DIR}/mast3r_outputs/archive/mast3r_outputs"
PROBE_DIR = f"{SHARED_DIR}/mast3r_outputs/archive/auth_probes"

print(f"\nEnrollment dir: {ENROLLMENT_DIR}")
print(f"Probe dir:      {PROBE_DIR}")
print(f"Enrollment dir exists: {os.path.isdir(ENROLLMENT_DIR)}")
print(f"Probe dir exists:      {os.path.isdir(PROBE_DIR)}")
```

**Expected output:**
```
GPU: Tesla T4 (15.0 GB) — descriptor matching will use GPU
Mounted at /content/drive
Enrollment dir exists: True
Probe dir exists:      True
```

If either directory shows `False`, see [Troubleshooting](#8-troubleshooting).

---

### Cell 2: Clone Repo & Configure Python Path

```python
# ============================================================
# Cell 2: Clone Repo & Configure Python Path
# ============================================================

import sys

REPO_URL = "https://github.com/gaelgm03/ai-visual-computing-pbl.git"
BRANCH = "main"  # Change to your feature branch if needed
REPO_DIR = "/content/ai-visual-computing-pbl"

if not os.path.exists(REPO_DIR):
    !git clone --depth 1 {REPO_URL} {REPO_DIR}

%cd {REPO_DIR}
!git fetch origin && git checkout {BRANCH} && git pull origin {BRANCH}

# Appendix C Cell 4: Install project dependencies
!pip install -r requirements.txt

sys.path.insert(0, REPO_DIR)
print(f"\nRepo ready at {REPO_DIR}, branch: {BRANCH}")
```

---

### Cell 3: Discover .npz Files

```python
# ============================================================
# Cell 3: Discover Available .npz Files
# ============================================================

import numpy as np
from pathlib import Path

def discover_data(enrollment_dir, probe_dir):
    """Find all enrollment/probe pairs by matching person names."""
    enrollments = {}
    probes = {}

    if os.path.isdir(enrollment_dir):
        for f in os.listdir(enrollment_dir):
            if f.endswith("_enrollment.npz"):
                name = f.replace("_enrollment.npz", "")
                enrollments[name] = os.path.join(enrollment_dir, f)

    if os.path.isdir(probe_dir):
        for f in os.listdir(probe_dir):
            if f.endswith("_probe.npz"):
                name = f.replace("_probe.npz", "")
                probes[name] = os.path.join(probe_dir, f)

    subjects = sorted(set(enrollments.keys()) & set(probes.keys()))
    return subjects, enrollments, probes


subjects, enrollments, probes = discover_data(ENROLLMENT_DIR, PROBE_DIR)

print(f"Found {len(subjects)} subjects with both enrollment and probe data:")
for s in subjects:
    e = np.load(enrollments[s])
    p = np.load(probes[s])
    print(f"  {s}: enrollment={e['point_cloud'].shape[0]:,} pts, "
          f"probe={p['point_cloud'].shape[0]:,} pts")

if not subjects:
    print("\nNo matching enrollment/probe pairs found!")
    print(f"  Check that {ENROLLMENT_DIR} has *_enrollment.npz files")
    print(f"  and {PROBE_DIR} has *_probe.npz files")
```

---

### Cell 4: Inspect Data Format

```python
# ============================================================
# Cell 4: Inspect Data Format
# ============================================================

sample = np.load(enrollments[subjects[0]], allow_pickle=True)
print("Keys:", list(sample.keys()))
for key in sample.keys():
    arr = sample[key]
    if hasattr(arr, 'shape'):
        print(f"  {key}: shape={arr.shape}, dtype={arr.dtype}")
    else:
        print(f"  {key}: {type(arr)}")

# Check descriptor normalization
desc = sample["descriptors"]
norms = np.linalg.norm(desc, axis=1)
print(f"\nDescriptor norms: min={norms.min():.3f}, max={norms.max():.3f}, mean={norms.mean():.3f}")
if abs(norms.mean() - 1.0) > 0.1:
    print("Descriptors are NOT unit-normalized — the matcher will normalize internally.")
else:
    print("Descriptors appear unit-normalized.")

# Check for ArcFace embeddings (v2.0 templates, added 2026-02-10)
HAS_EMBEDDINGS = "face_embedding" in sample
if HAS_EMBEDDINGS:
    emb = sample["face_embedding"]
    print(f"\nArcFace embedding: shape={emb.shape}, norm={np.linalg.norm(emb):.4f}")
    print("Template version: v2.0 (with identity embeddings)")
else:
    print("\nNo face_embedding found — template version v1.0")
    print("Run scripts/augment_npz_with_embeddings.py (on WSL) to add ArcFace embeddings.")
```

---

### Cell 5: Visualize Point Clouds

```python
# ============================================================
# Cell 5: Visualize Point Cloud (CS2DS-share.md S4.2)
# ============================================================

import plotly.graph_objects as go
from plotly.subplots import make_subplots

def visualize_point_cloud(points, colors=None, title="Point Cloud", max_points=10000):
    """Interactive 3D point cloud visualization."""
    if len(points) > max_points:
        idx = np.random.choice(len(points), max_points, replace=False)
        points = points[idx]
        if colors is not None:
            colors = colors[idx]

    if colors is not None:
        color_str = [f'rgb({r},{g},{b})' for r, g, b in colors]
    else:
        color_str = points[:, 2]

    fig = go.Figure(data=[go.Scatter3d(
        x=points[:, 0], y=points[:, 1], z=points[:, 2],
        mode='markers',
        marker=dict(size=1.5, color=color_str, opacity=0.8),
    )])
    fig.update_layout(
        title=title,
        scene=dict(aspectmode='data'),
        width=800, height=600,
    )
    return fig


# Show enrollment and probe for the first subject
person = subjects[0]
e_data = np.load(enrollments[person])
p_data = np.load(probes[person])

fig = visualize_point_cloud(
    e_data["point_cloud"], e_data["colors"],
    title=f"{person} — Enrollment ({e_data['point_cloud'].shape[0]:,} pts)"
)
fig.show()

fig = visualize_point_cloud(
    p_data["point_cloud"], p_data["colors"],
    title=f"{person} — Probe ({p_data['point_cloud'].shape[0]:,} pts)"
)
fig.show()
```

Use mouse drag to rotate, scroll to zoom. Verify that the face shape is recognizable.

---

### Cell 6: Initialize Matchers

> Updated 2026-02-10: Added `ArcFaceEmbeddingMatcher` and `MultiModalFusion` for 3-way matching.

```python
# ============================================================
# Cell 6: Initialize Matchers (updated 2026-02-10: ArcFace + MultiModalFusion)
# ============================================================

from core.matching.geometric_matcher import ICPGeometricMatcher
from core.matching.descriptor_matcher import NNDescriptorMatcher
from core.matching.score_fusion import WeightedFusion

config = {
    "icp": {
        "max_iterations": 50,
        "convergence_threshold": 1e-6,
        "max_correspondence_distance": 0.05,
    },
    "chamfer_alpha": 30.0,
    "geometric_subsample": 10000,
    "descriptor_subsample": 15000,
    "match_ratio_weight": 0.4,
    "avg_similarity_weight": 0.6,
    "geometric_weight": 0.4,
    "descriptor_weight": 0.6,
    "accept_threshold": 0.65,
}

geo_matcher = ICPGeometricMatcher(config)
desc_matcher = NNDescriptorMatcher(config)
fusion = WeightedFusion(config)

# --- ArcFace embedding matcher (added 2026-02-10) ---
emb_matcher = None
multi_fusion = None
if HAS_EMBEDDINGS:
    from core.matching.embedding_matcher import ArcFaceEmbeddingMatcher
    from core.matching.score_fusion import MultiModalFusion

    emb_matcher = ArcFaceEmbeddingMatcher({"embedding_dim": 512})

    multi_config = {
        "embedding_weight": 0.40,
        "geometric_weight": 0.10,
        "descriptor_weight": 0.50,
        "accept_threshold": 0.65,
    }
    multi_fusion = MultiModalFusion(multi_config)

    print("Matchers initialized (3-way with ArcFace):")
    print(f"  Embedding: ArcFace cosine similarity (weight={multi_config['embedding_weight']})")
    print(f"  Geometric: ICP + Chamfer (weight={multi_config['geometric_weight']})")
    print(f"  Descriptor: Reciprocal NN (weight={multi_config['descriptor_weight']})")
    print(f"  Fusion: MultiModalFusion, threshold={multi_config['accept_threshold']}")
else:
    print("Matchers initialized (legacy 2-way, no ArcFace embeddings):")
    print(f"  Geometric: ICP + Chamfer (subsample={config['geometric_subsample']})")
    print(f"  Descriptor: Reciprocal NN (subsample={config['descriptor_subsample']})")
    print(f"  Fusion: geo={config['geometric_weight']}, desc={config['descriptor_weight']}, threshold={config['accept_threshold']}")
```

Matcher roles:

| Matcher | Method | Input | Output |
|---------|--------|-------|--------|
| `ArcFaceEmbeddingMatcher` | Cosine similarity of L2-normalized 512-dim embeddings | Two embeddings `(512,)` | Score [0, 1] (added 2026-02-10) |
| `ICPGeometricMatcher` | ICP alignment > Chamfer distance > `exp(-alpha*d)` | Two point clouds `(N,3)` | Score [0, 1] |
| `NNDescriptorMatcher` | L2-normalize > Reciprocal NN > match_ratio + cosine_sim | Two descriptor sets `(N,24)` | Score [0, 1] (disabled by default) |
| `MultiModalFusion` | `0.7*emb + 0.3*geo + 0.0*desc` > threshold | Dict of scores | Final score + accept/reject (added 2026-02-10) |

---

### Cell 7: Genuine Pair Test (Same Person)

> Updated 2026-02-10: Added ArcFace embedding comparison when available.

```python
# ============================================================
# Cell 7: Single Genuine Pair Test (updated 2026-02-10)
# ============================================================

import time
from core.matching.interfaces import MatchResult

person = subjects[0]
enrollment = np.load(enrollments[person], allow_pickle=True)
probe = np.load(probes[person], allow_pickle=True)

print(f"=== Genuine pair: {person} vs {person} ===")

t0 = time.time()
geo_result = geo_matcher.compare(probe["point_cloud"], enrollment["point_cloud"])
t1 = time.time()
desc_result = desc_matcher.compare(
    probe["descriptors"], enrollment["descriptors"],
    probe["point_cloud"], enrollment["point_cloud"],
)
t2 = time.time()

# ArcFace embedding comparison (added 2026-02-10)
if HAS_EMBEDDINGS and emb_matcher is not None:
    emb_result = emb_matcher.compare(probe["face_embedding"], enrollment["face_embedding"])
    t3 = time.time()
    final_result = multi_fusion.fuse({
        "embedding": emb_result,
        "geometric": geo_result,
        "descriptor": desc_result,
    })
    print(f"  Embedding:  {emb_result.score:.3f}  (raw cosine: {emb_result.details.get('raw_cosine_similarity', 'N/A'):.3f})")
else:
    t3 = time.time()
    final_result = fusion.fuse(geo_result, desc_result)

print(f"  Geometric:  {geo_result.score:.3f}  (Chamfer: {geo_result.details.get('chamfer_distance', 'N/A')})")
print(f"  Descriptor: {desc_result.score:.3f}  (Match ratio: {desc_result.details.get('match_ratio', 0):.3f}, "
      f"Avg sim: {desc_result.details.get('avg_cosine_similarity', 0):.3f})")
print(f"  Fused:      {final_result.score:.3f}  is_match={final_result.is_match}")
print(f"  Time: geo={t1-t0:.2f}s, desc={t2-t1:.2f}s, total={t3-t0:.2f}s")
print(f"  Backend: desc={desc_result.details.get('backend', 'unknown')}")
```

**Expected result**: With ArcFace: Fused >= 0.55, `is_match=True`. Without: Fused >= 0.65.

---

### Cell 8: Impostor Pair Test (Different Person)

```python
# ============================================================
# Cell 8: Single Impostor Pair Test (updated 2026-02-10)
# ============================================================

if len(subjects) >= 2:
    person_a = subjects[0]
    person_b = subjects[1]
    enrollment_a = np.load(enrollments[person_a], allow_pickle=True)
    probe_b = np.load(probes[person_b], allow_pickle=True)

    geo_result = geo_matcher.compare(probe_b["point_cloud"], enrollment_a["point_cloud"])
    desc_result = desc_matcher.compare(
        probe_b["descriptors"], enrollment_a["descriptors"],
        probe_b["point_cloud"], enrollment_a["point_cloud"],
    )

    if HAS_EMBEDDINGS and emb_matcher is not None:
        emb_result = emb_matcher.compare(probe_b["face_embedding"], enrollment_a["face_embedding"])
        final_result = multi_fusion.fuse({
            "embedding": emb_result, "geometric": geo_result, "descriptor": desc_result,
        })
        print(f"=== Impostor pair: {person_b} vs {person_a} ===")
        print(f"  Embedding:  {emb_result.score:.3f}  (raw cosine: {emb_result.details.get('raw_cosine_similarity', 'N/A'):.3f})")
    else:
        final_result = fusion.fuse(geo_result, desc_result)
        print(f"=== Impostor pair: {person_b} vs {person_a} ===")

    print(f"  Geometric:  {geo_result.score:.3f}")
    print(f"  Descriptor: {desc_result.score:.3f}")
    print(f"  Fused:      {final_result.score:.3f}  is_match={final_result.is_match}")
else:
    print("Need at least 2 subjects for impostor test")
```

**Expected result**: With ArcFace: Fused < 0.55, `is_match=False`. Without: Fused < 0.65.

---

### Cell 9: All-vs-All Matching

> Updated 2026-02-10: Added ArcFace embedding comparison in the matching loop.

```python
# ============================================================
# Cell 9: All-vs-All Matching (updated 2026-02-10: ArcFace)
# ============================================================

from tqdm import tqdm

similarities = []
labels = []  # 1 = genuine, 0 = impostor
pair_info = []

# Cache loaded data to avoid re-reading
enrollment_cache = {}
probe_cache = {}
for s in subjects:
    enrollment_cache[s] = np.load(enrollments[s], allow_pickle=True)
    probe_cache[s] = np.load(probes[s], allow_pickle=True)

total_pairs = len(subjects) ** 2
print(f"Running {total_pairs} pairs ({len(subjects)} subjects x {len(subjects)} enrollments)...")
if HAS_EMBEDDINGS:
    print("  Mode: 3-way (ArcFace + Geometric + Descriptor)")
else:
    print("  Mode: Legacy 2-way (Geometric + Descriptor)")

for probe_person in tqdm(subjects, desc="Matching"):
    p_data = probe_cache[probe_person]

    for enroll_person in subjects:
        e_data = enrollment_cache[enroll_person]
        is_genuine = int(probe_person == enroll_person)

        geo_result = geo_matcher.compare(
            p_data["point_cloud"], e_data["point_cloud"]
        )
        desc_result = desc_matcher.compare(
            p_data["descriptors"], e_data["descriptors"],
            p_data["point_cloud"], e_data["point_cloud"],
        )

        info = {
            "probe": probe_person,
            "enrollment": enroll_person,
            "genuine": is_genuine,
            "geo_score": geo_result.score,
            "desc_score": desc_result.score,
        }

        # ArcFace embedding matching (added 2026-02-10)
        if HAS_EMBEDDINGS and emb_matcher is not None:
            emb_result = emb_matcher.compare(
                p_data["face_embedding"], e_data["face_embedding"]
            )
            final_result = multi_fusion.fuse({
                "embedding": emb_result,
                "geometric": geo_result,
                "descriptor": desc_result,
            })
            info["emb_score"] = emb_result.score
            info["emb_raw_cosine"] = emb_result.details.get("raw_cosine_similarity", 0)
        else:
            final_result = fusion.fuse(geo_result, desc_result)

        info["fused_score"] = final_result.score
        similarities.append(final_result.score)
        labels.append(is_genuine)
        pair_info.append(info)

similarities = np.array(similarities)
labels = np.array(labels)

print(f"\nTotal pairs: {len(similarities)}")
print(f"  Genuine:  {labels.sum()} ({labels.mean()*100:.1f}%)")
print(f"  Impostor: {(1-labels).sum().astype(int)} ({(1-labels).mean()*100:.1f}%)")
print(f"\nGenuine score range:  [{similarities[labels==1].min():.3f}, {similarities[labels==1].max():.3f}]")
print(f"Impostor score range: [{similarities[labels==0].min():.3f}, {similarities[labels==0].max():.3f}]")
```

**Estimated time**: 5 subjects (25 pairs) ~1-3 min with GPU, ~5-10 min on CPU.

---

### Cell 10: Evaluation Metrics

```python
# ============================================================
# Cell 10: Evaluate with FaceRecognitionEvaluator
# ============================================================

from core.evaluation import FaceRecognitionEvaluator

evaluator = FaceRecognitionEvaluator(threshold=config["accept_threshold"])
eval_result = evaluator.evaluate(
    similarities=similarities.tolist(),
    labels=labels.tolist(),
    plot=True,
)

print(f"\n{'='*50}")
print(f"EVALUATION RESULTS (threshold={eval_result.threshold:.2f})")
print(f"{'='*50}")
print(f"  Accuracy:  {eval_result.accuracy:.3f}")
print(f"  Precision: {eval_result.precision:.3f}")
print(f"  Recall:    {eval_result.recall:.3f}")
print(f"  F1 Score:  {eval_result.f1_score:.3f}")
print(f"  FAR:       {eval_result.far:.3f}")
print(f"  TAR:       {eval_result.tar:.3f}")
print(f"  EER:       {eval_result.eer:.3f} (at threshold={eval_result.eer_threshold:.3f})")
print(f"  AUC:       {eval_result.auc_score:.3f}")
```

Four diagnostic plots are generated automatically (see [Interpreting Results](#6-interpreting-results)).

| Metric | Description | Ideal |
|--------|-------------|-------|
| Accuracy | Overall correct rate | 1.0 |
| Precision | How accurate "accept" decisions are | 1.0 |
| Recall | Fraction of genuine pairs correctly accepted | 1.0 |
| F1 Score | Harmonic mean of Precision and Recall | 1.0 |
| FAR | Fraction of impostors incorrectly accepted | 0.0 |
| TAR | Fraction of genuine pairs correctly accepted | 1.0 |
| EER | Error rate where FAR = FRR | 0.0 |
| AUC | Area Under ROC Curve | 1.0 |

---

### Cell 11: Per-Path Score Distributions

> Updated 2026-02-10: Added 4th subplot for ArcFace embedding scores.

```python
# ============================================================
# Cell 11: Per-Path Score Distributions (updated 2026-02-10)
# ============================================================

import matplotlib.pyplot as plt

geo_scores = np.array([p['geo_score'] for p in pair_info])
desc_scores = np.array([p['desc_score'] for p in pair_info])
fused_scores = np.array([p['fused_score'] for p in pair_info])

if HAS_EMBEDDINGS:
    emb_scores = np.array([p.get('emb_score', 0) for p in pair_info])
    fig, axes = plt.subplots(1, 4, figsize=(24, 5))
    score_sets = [geo_scores, desc_scores, emb_scores, fused_scores]
    titles = ['Geometric (ICP + Chamfer)', 'Descriptor (Reciprocal NN)',
              'Embedding (ArcFace)', 'Fused (MultiModal)']
    threshold = multi_config['accept_threshold']
else:
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))
    score_sets = [geo_scores, desc_scores, fused_scores]
    titles = ['Geometric (ICP + Chamfer)', 'Descriptor (Reciprocal NN)', 'Fused (Weighted)']
    threshold = config['accept_threshold']

for ax, scores, title in zip(axes, score_sets, titles):
    ax.hist(scores[labels == 1], bins=20, alpha=0.7, label='Genuine', color='green')
    ax.hist(scores[labels == 0], bins=20, alpha=0.7, label='Impostor', color='red')
    ax.axvline(x=threshold, color='black', linestyle='--', label='Threshold')
    ax.set_title(title)
    ax.set_xlabel('Score')
    ax.set_ylabel('Count')
    ax.legend()

plt.tight_layout()
plt.show()
```

Higher separation between Genuine (green) and Impostor (red) distributions indicates better discriminative ability. With ArcFace embeddings, the Embedding subplot should show the clearest separation.

---

### Cell 12: Score Matrix Heatmap

```python
# ============================================================
# Cell 12: Score Matrix Heatmap
# ============================================================

n = len(subjects)
score_matrix = fused_scores.reshape(n, n)

fig = go.Figure(data=go.Heatmap(
    z=score_matrix,
    x=subjects,
    y=subjects,
    colorscale='RdYlGn',
    zmin=0, zmax=1,
    text=np.round(score_matrix, 2),
    texttemplate="%{text}",
))
fig.update_layout(
    title="Matching Score Matrix (Probe vs Enrollment)",
    xaxis_title="Enrollment",
    yaxis_title="Probe",
    width=max(500, 80 * n),
    height=max(400, 70 * n),
)
fig.show()
```

Diagonal cells (same person) should show high scores (green); off-diagonal (different person) should show low scores (red).

---

### Cell 13: Weight Optimization (Grid Search)

> Updated 2026-02-10: 3-way grid search over (embedding, geometric, descriptor) weights when ArcFace is available.

```python
# ============================================================
# Cell 13: Weight Optimization (updated 2026-02-10: 3-way grid search)
# ============================================================

from sklearn.metrics import f1_score as sk_f1_score

results_grid = []

if HAS_EMBEDDINGS:
    # 3-way grid search: (w_emb, w_geo, w_desc) must sum to 1.0
    step = 0.05
    for w_emb in np.arange(0.0, 1.0 + step, step):
        for w_geo in np.arange(0.0, 1.0 - w_emb + step, step):
            w_desc = round(1.0 - w_emb - w_geo, 2)
            if w_desc < -0.01:
                continue
            w_desc = max(0.0, w_desc)

            fused = w_emb * emb_scores + w_geo * geo_scores + w_desc * desc_scores

            best_f1, best_thresh = 0.0, 0.5
            for thresh in np.arange(0.1, 0.95, 0.01):
                preds = (fused >= thresh).astype(int)
                f1_val = sk_f1_score(labels, preds, zero_division=0)
                if f1_val > best_f1:
                    best_f1 = f1_val
                    best_thresh = thresh

            results_grid.append({
                'w_emb': round(w_emb, 2),
                'w_geo': round(w_geo, 2),
                'w_desc': round(w_desc, 2),
                'best_f1': best_f1,
                'best_threshold': round(best_thresh, 2),
            })

    best = max(results_grid, key=lambda x: x['best_f1'])

    # Show top 10
    top10 = sorted(results_grid, key=lambda x: -x['best_f1'])[:10]
    print(f"{'w_emb':>6} {'w_geo':>6} {'w_desc':>7} {'Best F1':>8} {'Threshold':>10}")
    print("-" * 45)
    for r in top10:
        marker = " <-- BEST" if r == best else ""
        print(f"{r['w_emb']:>6.2f} {r['w_geo']:>6.2f} {r['w_desc']:>7.2f} "
              f"{r['best_f1']:>8.3f} {r['best_threshold']:>10.2f}{marker}")

    print(f"\nOptimal: embedding_weight={best['w_emb']:.2f}, "
          f"geometric_weight={best['w_geo']:.2f}, "
          f"descriptor_weight={best['w_desc']:.2f}, "
          f"threshold={best['best_threshold']:.2f}, "
          f"F1={best['best_f1']:.3f}")

else:
    # Legacy 2-way grid search
    alphas = np.arange(0.0, 1.05, 0.05)
    for alpha in alphas:
        beta = 1.0 - alpha
        fused = alpha * geo_scores + beta * desc_scores

        best_f1, best_thresh = 0.0, 0.5
        for thresh in np.arange(0.1, 0.95, 0.01):
            preds = (fused >= thresh).astype(int)
            f1_val = sk_f1_score(labels, preds, zero_division=0)
            if f1_val > best_f1:
                best_f1 = f1_val
                best_thresh = thresh

        results_grid.append({
            'alpha': round(alpha, 2),
            'beta': round(beta, 2),
            'best_f1': best_f1,
            'best_threshold': round(best_thresh, 2),
        })

    best = max(results_grid, key=lambda x: x['best_f1'])

    print(f"{'Alpha':>6} {'Beta':>6} {'Best F1':>8} {'Threshold':>10}")
    print("-" * 35)
    for r in results_grid:
        marker = " <-- BEST" if r == best else ""
        print(f"{r['alpha']:>6.2f} {r['beta']:>6.2f} {r['best_f1']:>8.3f} {r['best_threshold']:>10.2f}{marker}")

    print(f"\nOptimal: geometric_weight={best['alpha']:.2f}, "
          f"descriptor_weight={best['beta']:.2f}, "
          f"threshold={best['best_threshold']:.2f}, "
          f"F1={best['best_f1']:.3f}")
```

---

### Cell 14: Re-evaluate with Optimal Parameters

```python
# ============================================================
# Cell 14: Re-evaluate with Optimal Parameters (updated 2026-02-10)
# ============================================================

if HAS_EMBEDDINGS:
    optimal_similarities = (best['w_emb'] * emb_scores
                           + best['w_geo'] * geo_scores
                           + best['w_desc'] * desc_scores)
    weight_str = f"emb={best['w_emb']:.2f}, geo={best['w_geo']:.2f}, desc={best['w_desc']:.2f}"
else:
    optimal_similarities = best['alpha'] * geo_scores + best['beta'] * desc_scores
    weight_str = f"geo={best['alpha']:.2f}, desc={best['beta']:.2f}"

optimal_evaluator = FaceRecognitionEvaluator(threshold=best['best_threshold'])

optimal_result = optimal_evaluator.evaluate(
    optimal_similarities.tolist(),
    labels.tolist(),
    plot=True,
)

print(f"\n{'='*50}")
print(f"OPTIMIZED RESULTS")
print(f"{'='*50}")
print(f"  Weights:   {weight_str}")
print(f"  Threshold: {best['best_threshold']:.2f}")
print(f"  Accuracy:  {optimal_result.accuracy:.3f}")
print(f"  F1 Score:  {optimal_result.f1_score:.3f}")
print(f"  FAR:       {optimal_result.far:.3f}")
print(f"  TAR:       {optimal_result.tar:.3f}")
print(f"  EER:       {optimal_result.eer:.3f}")
print(f"  AUC:       {optimal_result.auc_score:.3f}")
```

---

### Cell 15: Recommended config.yaml Values + Save Results

```python
# ============================================================
# Cell 15: Recommended config.yaml Values (updated 2026-02-10)
# ============================================================

print("=" * 60)
print("RECOMMENDED CONFIG.YAML VALUES")
print("=" * 60)

if HAS_EMBEDDINGS:
    print(f"""
matching:
  embedding_weight: {best['w_emb']:.2f}     # ArcFace (primary identity)
  geometric_weight: {best['w_geo']:.2f}     # ICP + Chamfer (supplementary)
  descriptor_weight: {best['w_desc']:.2f}    # MASt3R descriptors
  accept_threshold: {best['best_threshold']:.2f}    # Optimized threshold
""")
else:
    print(f"""
matching:
  geometric_weight: {best['alpha']:.2f}     # Optimized alpha
  descriptor_weight: {best['beta']:.2f}    # Optimized beta
  accept_threshold: {best['best_threshold']:.2f}    # Optimized threshold
""")

print(f"Based on {len(subjects)} subjects, {len(similarities)} total pairs")
print(f"F1={optimal_result.f1_score:.3f}, EER={optimal_result.eer:.3f}, AUC={optimal_result.auc_score:.3f}")

# Save figures to Drive
figures_dir = f"{SHARED_DIR}/evaluation_results/figures"
optimal_evaluator.evaluate(
    optimal_similarities.tolist(),
    labels.tolist(),
    plot=False,
    save_dir=figures_dir,
)
print(f"\nFigures saved to {figures_dir}")

# ArcFace-only evaluation for comparison (added 2026-02-10)
if HAS_EMBEDDINGS:
    print(f"\n{'='*60}")
    print("ARCFACE-ONLY EVALUATION (for comparison)")
    print(f"{'='*60}")
    emb_only_evaluator = FaceRecognitionEvaluator(threshold=0.5)
    emb_only_result = emb_only_evaluator.evaluate(
        emb_scores.tolist(), labels.tolist(), plot=False,
    )
    print(f"  ArcFace-only AUC: {emb_only_result.auc_score:.3f}")
    print(f"  ArcFace-only EER: {emb_only_result.eer:.3f}")
    print(f"  → This shows the raw discriminative power of ArcFace alone.")
```

Copy the output values into the `matching` section of `config.yaml` to apply them to the production system.

---

## 6. Interpreting Results

### Four Diagnostic Plots

#### 1. Similarity Score Distribution
- **Green**: Genuine (same person), **Red**: Impostor (different person), **Black dashed**: Threshold
- **Good result**: Green and red distributions do not overlap

#### 2. Confusion Matrix
- **TN**: Impostor correctly rejected, **FP**: Impostor incorrectly accepted (FAR)
- **FN**: Genuine incorrectly rejected (FRR), **TP**: Genuine correctly accepted (TAR)

#### 3. ROC Curve
- **Ideal**: Curve hugs the top-left corner (AUC = 1.0)
- **Dashed line**: Random guessing (AUC = 0.5)

#### 4. Metrics Summary (Bar Chart)
- Bar chart of all 6 key metrics at a glance

---

## 7. Parameter Tuning

Adjustable via the `config` dictionary in Cell 6.

| Parameter | Default | Description |
|-----------|---------|-------------|
| `embedding_weight` | `0.40` | ArcFace embedding score weight (added 2026-02-10) |
| `geometric_weight` | `0.10` | Geometric score weight |
| `descriptor_weight` | `0.50` | MASt3R descriptor weight |
| `accept_threshold` | `0.65` | Accept/reject threshold |
| `icp.max_iterations` | `50` | ICP iteration count. More = better accuracy, slower |
| `icp.max_correspondence_distance` | `0.05` | Max correspondence distance (meters) |
| `chamfer_alpha` | `30.0` | Decay factor in `exp(-alpha*d)` |
| `geometric_subsample` | `10000` | Point cloud subsample limit |
| `match_ratio_weight` | `0.4` | Weight for match ratio in descriptor score |
| `avg_similarity_weight` | `0.6` | Weight for average cosine similarity |
| `descriptor_subsample` | `15000` | Descriptor subsample limit |

> **Tip**: Cell 13's grid search automatically finds optimal weights and threshold values. With ArcFace embeddings, it searches over 3 weight dimensions.

---

## 8. Troubleshooting

### Google Drive Directory Not Found (`exists: False`)

**Solution**:
1. Right-click the `face-auth-data` folder in Google Drive > "Add shortcut to Drive" > place in My Drive root
2. Alternative: Directly modify `SHARED_DIR` in Cell 1

```python
# For shared drives
SHARED_DIR = "/content/drive/Shareddrives/YourDriveName/face-auth-data"
```

### `No matching enrollment/probe pairs found!`

**Check**:
- Enrollment files must be named `<name>_enrollment.npz`, probes `<name>_probe.npz`
- The `<name>` portion must match exactly (case-sensitive)

### `open3d` Installation Fails

The pipeline works without open3d. The Geometric Matcher automatically falls back to scipy SVD-based ICP.

### GPU Errors

The Descriptor Matcher has a built-in CPU fallback for `RuntimeError`. Check the `backend` field in output:
- `gpu_matmul`: Using GPU
- `cpu_kdtree`: Using CPU
- `cpu_kdtree (gpu_fallback)`: Fell back to CPU after GPU attempt

### Out of Memory (OOM)

Reduce subsample limits: `geometric_subsample: 5000`, `descriptor_subsample: 8000`

### Descriptor Score is 0.000

**Cause**: The `descriptors` array in the `.npz` may contain NaN/Inf values. These can arise from MASt3R's FP16 inference, image edges, or padding regions. The `descriptor_matcher.py` `_filter_invalid()` method removes these automatically, but if fewer than 5 valid descriptors remain after filtering, the score becomes 0.0.

**Verification**:
```python
desc = np.load("path/to/file.npz")["descriptors"]
print(f"NaN: {np.isnan(desc).any()}, Inf: {np.isinf(desc).any()}")
print(f"Valid rows: {np.isfinite(desc).all(axis=1).sum()} / {len(desc)}")
```

**Fix**: Regenerate the `.npz` files (upstream `_extract_aligned_descriptors` now includes NaN/Inf filtering). If the `sparse_ga.py` descriptor cache patch is applied during regeneration, descriptors are stored in 1:1 correspondence with the 3D point cloud and go through the same spatial filters (dedup/outlier/cluster).

### sparse_ga.py Patch (Descriptor Support)

When regenerating `.npz` files, the following 4 lines must be added to the `forward_mast3r()` function in `third_party/mast3r/mast3r/cloud_opt/sparse_ga.py` (manual patch, similar to the existing `.get()` patch):

```python
# Add after line 594 (after torch.save(to_cpu((X22, ...)))):

            # save per-view descriptors for downstream extraction (face-auth patch)
            desc_path1 = cache_path + f'/desc/{idx1}/{idx2}.pth'
            desc_path2 = cache_path + f'/desc/{idx2}/{idx1}.pth'
            torch.save(to_cpu(descs[0]), mkdir_for(desc_path1))  # desc11: img1's self-desc
            torch.save(to_cpu(descs[2]), mkdir_for(desc_path2))  # desc22: img2's self-desc
```

This patch enables `global_alignment.py` to load per-view descriptors from the forward pass cache, pairing them with `get_dense_pts3d()` output by pixel index for 1:1 correspondence.

### All Matching Scores Are 0.0

Check the Cell 4 output for data shapes. Likely causes: empty point cloud (`< 10 points`) or descriptor dimension mismatch.

---

## 9. Directions for Accuracy Improvement

> Updated 2026-02-10: ArcFace integration (Level 3a) is now implemented. The remaining directions focus on further refinement.

### Background

The original system (v1.0) used MASt3R descriptors as the identity signal, yielding AUC ≈ 0.53 and EER ≈ 0.46 (near random chance). Grid search found `descriptor_weight=0.00` as optimal — MASt3R descriptors have **zero identity discrimination** (they are designed for view correspondence, not person identification).

**Solution implemented (2026-02-10)**: ArcFace (insightface buffalo_l) added as the primary identity signal. MASt3R retained for 3D reconstruction and anti-spoofing only.

### Preparing v2.0 Templates (ArcFace Embeddings)

Existing v1.0 .npz files can be augmented with ArcFace embeddings using the `augment_npz_with_embeddings.py` script. **This script runs on WSL** (not on Colab), as it requires access to the original source images from the dataset directory.

```bash
# On WSL (with venv activated):
python scripts/augment_npz_with_embeddings.py \
    --npz-dir /path/to/mast3r_outputs \
    --dataset-dir /path/to/dataset \
    --output-dir /path/to/augmented_outputs

# Or augment in-place:
python scripts/augment_npz_with_embeddings.py \
    --npz-dir /path/to/mast3r_outputs \
    --dataset-dir /path/to/dataset \
    --in-place
```

After augmentation, upload the v2.0 .npz files to Google Drive for Colab evaluation.

### Remaining Improvement Directions

#### a) Tune Geometric Matching (`chamfer_alpha`)

The distance-to-score conversion uses `score = exp(-30.0 * chamfer_distance)`. Adjusting `chamfer_alpha` can improve the supplementary geometric signal.

#### b) Increase Authentication Frame Count

Auth probes currently use 4 frames. Increasing to 8-12 frames improves MASt3R reconstruction quality and enrollment-probe shape agreement.

#### c) Landmark-Based Pre-Alignment

Pre-aligning using 3D facial landmarks (nose tip, eye corners) before ICP reduces local-optimum risk.

#### d) Score Normalization

z-score or min-max normalization on component scores before fusion.

#### e) ArcFace Quality Weighting

Weight individual frame embeddings by face detection confidence or blur score during aggregation. Currently uses uniform weighting across frames.

#### f) Future Architectural Enhancements

- **3D Morphable Model (FLAME)** fitting for pose-invariant shape comparison
- **Metric learning** on MASt3R descriptor space (if fine-tuning data available)
- **Multi-view ArcFace**: Extract embeddings from MASt3R-aligned frontalized views

---

## Related Documents

- `technical-architecture_whole.md` — Full system architecture (Appendix C: Colab environment setup)
- `CS2DS-share.md` — Matching algorithm specification (§5.1-5.3, §10)
- `config.yaml` — System configuration (`matching` + `face_embedding` sections)
- `core/matching/interfaces.py` — Abstract matcher interface definitions (incl. `EmbeddingMatcher`)
- `core/face_embedder.py` — ArcFace model wrapper (added 2026-02-10)
- `core/matching/embedding_matcher.py` — ArcFace cosine similarity matcher (added 2026-02-10)
- `scripts/augment_npz_with_embeddings.py` — Retrofit ArcFace embeddings into existing .npz files (added 2026-02-10)
